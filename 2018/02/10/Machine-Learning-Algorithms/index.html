<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>AI技术原理|机器学习算法 | Ribose Yim&#39;s Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="摘要 机器学习算法分类：监督学习、半监督学习、无监督学习、强化学习 基本的机器学习算法：线性回归、支持向量机(SVM)、最近邻居(KNN)、逻辑回归、决策树、k平均、随机森林、朴素贝叶斯、降维、梯度增强 公式、图示、案例">
<meta property="og:type" content="article">
<meta property="og:title" content="AI技术原理|机器学习算法">
<meta property="og:url" content="https://riboseyim.com/2018/02/10/Machine-Learning-Algorithms/index.html">
<meta property="og:site_name" content="Ribose Yim&#39;s Home">
<meta property="og:description" content="摘要 机器学习算法分类：监督学习、半监督学习、无监督学习、强化学习 基本的机器学习算法：线性回归、支持向量机(SVM)、最近邻居(KNN)、逻辑回归、决策树、k平均、随机森林、朴素贝叶斯、降维、梯度增强 公式、图示、案例">
<meta property="og:locale">
<meta property="og:image" content="https://semiengineering.com/wp-content/uploads/2018/06/Machine-Learning-Algorithms-2.jpg.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_LR.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Linear_Regression_2.jpg">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_SVM.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_SupportVectorMachine.jpg">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_KNN.gif">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_NearestNeighbors.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Learning_Vector_Quantization.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Logistic_Regression_1.gif">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Logistic_Regression.jpg">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_DT.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_DecisionTree.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_KM.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_RF.jpg">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_RandomForest.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Bayes.png">
<meta property="og:image" content="http://riboseyim-qiniu.riboseyim.com/banner-MLM-201803.png">
<meta property="article:published_time" content="2018-02-10T10:17:46.000Z">
<meta property="article:modified_time" content="2023-08-16T02:50:06.560Z">
<meta property="article:author" content="RiboseYim">
<meta property="article:tag" content="架构师">
<meta property="article:tag" content="数学与算法">
<meta property="article:tag" content="Machine-Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://semiengineering.com/wp-content/uploads/2018/06/Machine-Learning-Algorithms-2.jpg.png">
  
    <link rel="alternate" href="/atom.xml" title="Ribose Yim&#39;s Home" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  
    
  
  
<link rel="stylesheet" href="/css/style.css">

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-129742531-2', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


<meta name="generator" content="Hexo 5.4.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://riboseyim.com"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/tags/DevOps">DevOps</a>
        
          <a class="main-nav-link" href="/tags/Machine-Learning">机器学习</a>
        
          <a class="main-nav-link" href="/tags/Economist">经济学人</a>
        
          <a class="main-nav-link" href="/tags/Policy-Law">Policy&amp;Law</a>
        
          <a class="main-nav-link" href="/charts">图表</a>
        
          <a class="main-nav-link" href="/2017/02/09/eBook">电子书</a>
        
          <a class="main-nav-link" href="/2016/05/31/AboutMe">关于</a>
        
          <a class="main-nav-link" href="https://riboseyim.com">TechBlog</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ribose Yim&#39;s Home</a>
      </h1>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Machine-Learning-Algorithms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/10/Machine-Learning-Algorithms/" class="article-date">
  <time datetime="2018-02-10T10:17:46.000Z" itemprop="datePublished">2018-02-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/technology/">工程技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      AI技术原理|机器学习算法
    </h1>
  

      </header>
      
      <footer class="article-footer">
        <a data-url="https://riboseyim.com/2018/02/10/Machine-Learning-Algorithms/" data-id="ckwgm33m700ev7b1y6hohjnyg" class="article-share-link">分享</a>
        
        
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数学与算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/" rel="tag">架构师</a></li></ul>

      </footer>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li>机器学习算法分类：监督学习、半监督学习、无监督学习、强化学习</li>
<li>基本的机器学习算法：线性回归、支持向量机(SVM)、最近邻居(KNN)、逻辑回归、决策树、k平均、随机森林、朴素贝叶斯、降维、梯度增强</li>
<li>公式、图示、案例</li>
</ul>
<span id="more"></span>
<h2 id="机器学习算法分类"><a href="#机器学习算法分类" class="headerlink" title="机器学习算法分类"></a>机器学习算法分类</h2><p>机器学习算法大致可以分为：</p>
<ul>
<li>监督学习 | Supervised learning</li>
<li>半监督学习 | Semi-supervised learning</li>
<li>无监督学习 | Unsupervised learning</li>
<li>强化学习 | Reinforcement learning</li>
</ul>
<p><img src="https://semiengineering.com/wp-content/uploads/2018/06/Machine-Learning-Algorithms-2.jpg.png" alt="Machine-Learning-Algorithms"></p>
<h4 id="监督学习-Supervised-learning"><a href="#监督学习-Supervised-learning" class="headerlink" title="监督学习 | Supervised learning"></a>监督学习 | Supervised learning</h4><p>监督学习算法基于一组示例进行预测。在监督学习训练过程中，可以由训练数据集学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。</p>
<p>监督学习算法要求特定的输入/输出，一个常见的例子是根据当年和前几年的销售情况估算下一年的销售额。首先需要决定 <strong>使用哪种数据作为范例</strong>。例如，文字识别应用中一个手写的字符，或一行手写文字。监督学习主要算法包括神经网络、支持向量机、最近邻居法、朴素贝叶斯法、决策树等。</p>
<ul>
<li>分类（Classification）：当数据被用于预测分类变量时，监督学习也被称为分类。为图像分配标签或指示器（例如狗或猫）时就是这种情况。当只有两个标签时，这称为二进制分类（ binary classification）。当有两个以上的类别时，这些问题被称为多级分类（multi-class classification）。</li>
<li>回归（Regression）：当我们需要预测连续值时，就变成了回归问题。</li>
<li>预测（Forecasting）：根据过去和现在的数据对未来进行预测的过程。它最常用于分析趋势。</li>
</ul>
<h4 id="半监督学习-Semi-supervised-learning"><a href="#半监督学习-Semi-supervised-learning" class="headerlink" title="半监督学习 | Semi-supervised learning"></a>半监督学习 | Semi-supervised learning</h4><p>监督学习带来的挑战是标签数据可能非常昂贵而且耗时。如果标签有限，可以使用未标记的示例来增强监督式学习。因为在这种情况下机器没有完全监督，所以我们说机器是半监督的。使用半监督学习，您可以使用带有少量标签数据的未标记示例来提高学习的准确性。</p>
<h4 id="无监督学习-Unsupervised-learning"><a href="#无监督学习-Unsupervised-learning" class="headerlink" title="无监督学习 | Unsupervised learning"></a>无监督学习 | Unsupervised learning</h4><p>无监督学习算法没有特定的目标输出，算法将数据集分为不同的组。</p>
<p>在进行无监督学习时，机器会显示完全未标记的数据。它要求发现数据基础的内在模式，例如聚类结构（clustering structure），低维流形（a low-dimensional manifold）或稀疏树（sparse tree ）和图（graph）。</p>
<ul>
<li>聚类（Clustering）：对一组数据示例进行分组，使一个组（或一个聚类）中的示例与其他组中的示例更相似（根据某些标准）。这通常用于将整个数据集分成几个组。可以在每个组中进行分析以帮助用户找到固有模式。</li>
<li>降维（Dimension reduction）：减少需要考虑的变量数量。在许多应用中，原始数据具有非常高的维度特征，并且一些特征对于任务是多余的或不相关的。降维有助于找到数据内在真实的、潜在的关系。</li>
</ul>
<h4 id="强化学习-Reinforcement-learning"><a href="#强化学习-Reinforcement-learning" class="headerlink" title="强化学习 | Reinforcement learning"></a>强化学习 | Reinforcement learning</h4><p>强化学习强调通过基于环境的反馈行为分析、优化以取得最佳预期。机器尝试不同的场景来发现哪些行为能产生最大的回报，而不是被告知要采取何种行动。反复试验（Trial-and-error）和延迟奖励（delayed reward）是将强化学习与其他技术区分开来的关键。</p>
<p>强化学习普适性强，主要基于决策进行训练，算法根据输出结果（决策）的成功或错误来训练自己，通过大量经验训练优化后的算法将能够给出较好的预测。类似有机体在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。在运筹学和控制论的语境下，强化学习被称作“近似动态规划”（approximate dynamic programming，ADP）。</p>
<h2 id="机器学习算法列表"><a href="#机器学习算法列表" class="headerlink" title="机器学习算法列表"></a>机器学习算法列表</h2><ul>
<li>线性回归算法 Linear Regression</li>
<li>支持向量机算法 (Support Vector Machine,SVM)</li>
<li>最近邻居/k-近邻算法 (K-Nearest Neighbors,KNN)</li>
<li>逻辑回归算法 Logistic Regression</li>
<li>决策树算法 Decision Tree</li>
<li>k-平均算法 K-Means</li>
<li>随机森林算法 Random Forest</li>
<li>朴素贝叶斯算法 Naive Bayes</li>
<li>降维算法 Dimensional Reduction</li>
<li>梯度增强算法 Gradient Boosting</li>
</ul>
<h2 id="1-线性回归算法-Linear-Regression"><a href="#1-线性回归算法-Linear-Regression" class="headerlink" title="1. 线性回归算法 Linear Regression"></a>1. 线性回归算法 Linear Regression</h2><p>回归分析（Regression Analysis）是统计学的数据分析方法，目的在于了解两个或多个变量间是否相关、相关方向与强度，并建立数学模型以便观察特定变量来预测其它变量的变化情况。</p>
<p>线性回归算法（Linear Regression）的建模过程就是使用数据点来寻找最佳拟合线。公式，y = m<em>x + c，其中 y 是因变量，x 是自变量，利用给定的数据集求 m 和 c 的值。<br>线性回归又分为两种类型，即 <strong>简单线性回归（simple linear regression)</strong>，只有 1 个自变量；<em>*多变量回归（multiple regression)</em></em>，至少两组以上自变量。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_LR.png" alt=""> <img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Linear_Regression_2.jpg" alt=""></p>
<p>下面是一个线性回归示例：基于 Python scikit-learn 工具包描述。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, datasets</span><br><span class="line"></span><br><span class="line"><span class="comment">#digit dataset from sklearn</span></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line"><span class="comment">#create the LinearRegression model</span></span><br><span class="line">clf = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment">#set training set</span></span><br><span class="line">x, y = digits.data[:-<span class="number">1</span>], digits.target[:-<span class="number">1</span>]</span><br><span class="line"><span class="comment">#train model</span></span><br><span class="line">clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#predict</span></span><br><span class="line">y_pred = clf.predict([digits.data[-<span class="number">1</span>]])</span><br><span class="line">y_true = digits.target[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br><span class="line"><span class="built_in">print</span>(y_true)</span><br></pre></td></tr></table></figure>
<h2 id="2-支持向量机算法-Support-Vector-Machine-SVM"><a href="#2-支持向量机算法-Support-Vector-Machine-SVM" class="headerlink" title="2. 支持向量机算法(Support Vector Machine,SVM)"></a>2. 支持向量机算法(Support Vector Machine,SVM)</h2><p>支持向量机/网络算法(SVM)属于分类型算法。SVM模型将实例表示为空间中的点，将使用一条直线分隔数据点。需要注意的是，支持向量机需要对输入数据进行完全标记，仅直接适用于两类任务，应用将多类任务需要减少到几个二元问题。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_SVM.png" alt=""></p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_SupportVectorMachine.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"></span><br><span class="line"><span class="comment">#digit dataset from sklearn</span></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line"></span><br><span class="line"><span class="comment">#create the  Support Vector Classifier</span></span><br><span class="line">clf = svm.SVC(gamma = <span class="number">0.001</span>, C = <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set training set</span></span><br><span class="line">x, y = digits.data[:-<span class="number">1</span>], digits.target[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#train model</span></span><br><span class="line">clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#predict</span></span><br><span class="line">y_pred = clf.predict([digits.data[-<span class="number">1</span>]])</span><br><span class="line">y_true = digits.target[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br><span class="line"><span class="built_in">print</span>(y_true)</span><br></pre></td></tr></table></figure>
<h2 id="3-最近邻居-k-近邻算法-K-Nearest-Neighbors-KNN"><a href="#3-最近邻居-k-近邻算法-K-Nearest-Neighbors-KNN" class="headerlink" title="3. 最近邻居/k-近邻算法 (K-Nearest Neighbors,KNN)"></a>3. 最近邻居/k-近邻算法 (K-Nearest Neighbors,KNN)</h2><p>KNN算法是一种基于实例的学习，或者是局部近似和将所有计算推迟到分类之后的惰性学习。用最近的邻居（k）来预测未知数据点。k 值是预测精度的一个关键因素，无论是分类还是回归，衡量邻居的权重都非常有用，较近邻居的权重比较远邻居的权重大。</p>
<p>KNN 算法的缺点是对数据的局部结构非常敏感。计算量大，需要对数据进行规范化处理，使每个数据点都在相同的范围。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_KNN.gif" alt=""></p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_NearestNeighbors.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment">#digit dataset from sklearn</span></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line"></span><br><span class="line"><span class="comment">#create the  KNeighborsClassifier</span></span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set training set</span></span><br><span class="line">x, y = digits.data[:-<span class="number">1</span>], digits.target[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#train model</span></span><br><span class="line">clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#predict</span></span><br><span class="line">y_pred = clf.predict([digits.data[-<span class="number">1</span>]])</span><br><span class="line">y_true = digits.target[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br><span class="line"><span class="built_in">print</span>(y_true)</span><br></pre></td></tr></table></figure>
<p>延伸：KNN 的一个缺点是依赖于整个训练数据集，学习向量量化（Learning Vector Quantization，LVQ)是一种监督学习的人神经网络算法，允许你选择训练实例。LVQ 由数据驱动，搜索距离它最近的两个神经元，对于同类神经元采取拉拢，异类神经元采取排斥，最终得到数据的分布模式。如果基于 KNN 可以获得较好的数据集分类效果，利用 LVQ 可以减少存储训练数据集存储规模。典型的学习矢量量化算法有LVQ1、LVQ2和LVQ3，尤以LVQ2的应用最为广泛。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Learning_Vector_Quantization.png" alt=""></p>
<h2 id="4-逻辑回归算法-Logistic-Regression"><a href="#4-逻辑回归算法-Logistic-Regression" class="headerlink" title="4. 逻辑回归算法 Logistic Regression"></a>4. 逻辑回归算法 Logistic Regression</h2><p>逻辑回归算法（Logistic Regression）一般用于需要明确输出的场景，如某些事件的发生（预测是否会发生降雨）。通常，逻辑回归使用某种函数将概率值压缩到某一特定范围。<br>例如，Sigmoid 函数（S 函数）是一种具有 S 形曲线、用于二元分类的函数。它将发生某事件的概率值转换为 0, 1 的范围表示。</p>
<blockquote>
<p>Y = E ^（b0＋b1 <em> x）/（1 + E ^（b0＋b1 </em> x ））</p>
</blockquote>
<p>以上是一个简单的逻辑回归方程，B0，B1是常数。这些常数值将被计算获得，以确保预测值和实际值之间的误差最小。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Logistic_Regression_1.gif" alt=""></p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Logistic_Regression.jpg" alt=""></p>
<h2 id="5-决策树算法-Decision-Tree"><a href="#5-决策树算法-Decision-Tree" class="headerlink" title="5. 决策树算法 Decision Tree"></a>5. 决策树算法 Decision Tree</h2><p>决策树（Decision tree）是一种特殊的树结构，由一个决策图和可能的结果（例如成本和风险）组成，用来辅助决策。机器学习中，决策树是一个预测模型，树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，通常该算法用于解决分类问题。</p>
<p>一个决策树包含三种类型的节点：</p>
<ul>
<li>决策节点：通常用矩形框来表示</li>
<li>机会节点：通常用圆圈来表示</li>
<li>终结点：通常用三角形来表示</li>
</ul>
<p>简单决策树算法案例，确定人群中谁喜欢使用信用卡。考虑人群的年龄和婚姻状况，如果年龄在30岁或是已婚，人们更倾向于选择信用卡，反之则更少。<br>通过确定合适的属性来定义更多的类别，可以进一步扩展此决策树。在这个例子中，如果一个人结婚了，他超过30岁，他们更有可能拥有信用卡（100% 偏好）。测试数据用于生成决策树。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_DT.png" alt=""></p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_DecisionTree.png" alt=""></p>
<p><strong>注意</strong>：对于那些各类别样本数量不一致的数据，在决策树当中信息增益的结果偏向于那些具有更多数值的特征。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.hansmelo.com/2017/07/28/decision-trees/">Introduction to Decision Tree</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/4qQxB4AthVAYKggEV3BHFw">ThunderGBM：快成一道闪电的梯度提升决策树 | 机器之心  3月7日</a></li>
</ul>
<h2 id="6-k-平均算法-K-Means"><a href="#6-k-平均算法-K-Means" class="headerlink" title="6. k-平均算法 K-Means"></a>6. k-平均算法 K-Means</h2><p>k-平均算法(K-Means)是一种无监督学习算法，为聚类问题提供了一种解决方案。<br>K-Means 算法把 n 个点（可以是样本的一次观察或一个实例）划分到 k 个集群（cluster），使得每个点都属于离他最近的均值（即聚类中心，centroid）对应的集群。重复上述过程一直持续到重心不改变。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_KM.png" alt=""></p>
<h2 id="7-随机森林算法-Random-Forest"><a href="#7-随机森林算法-Random-Forest" class="headerlink" title="7. 随机森林算法 Random Forest"></a>7. 随机森林算法 Random Forest</h2><p>随机森林算法（Random Forest）的名称由 1995 年由贝尔实验室提出的random decision forests 而来，正如它的名字所说的那样，随机森林可以看作一个决策树的集合。<br>随机森林中每棵决策树估计一个分类，这个过程称为“投票（vote）”。理想情况下，我们根据每棵决策树的每个投票，选择最多投票的分类。</p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_RF.jpg" alt=""></p>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_RandomForest.png" alt=""></p>
<ul>
<li><strong>Paper</strong><a target="_blank" rel="noopener" href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">Random Forest |Leo Breiman | Statistics Department  University of California Berkeley</a></li>
</ul>
<h2 id="8-朴素贝叶斯算法-Naive-Bayes"><a href="#8-朴素贝叶斯算法-Naive-Bayes" class="headerlink" title="8. 朴素贝叶斯算法 Naive Bayes"></a>8. 朴素贝叶斯算法 Naive Bayes</h2><p>朴素贝叶斯算法（Naive Bayes）基于概率论的贝叶斯定理，应用非常广泛，从文本分类、垃圾邮件过滤器、医疗诊断等等。朴素贝叶斯适用于特征之间的相互独立的场景，例如利用花瓣的长度和宽度来预测花的类型。“朴素”的内涵可以理解为特征和特征之间独立性强。</p>
<p>与朴素贝叶斯算法密切相关的一个概念是最大似然估计(Maximum likelihood estimation)，历史上大部分的最大似然估计理论也都是在贝叶斯统计中得到大发展。例如，建立人口身高模型，很难有人力与物力去统计全国每个人的身高，但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取分布的均值与方差。</p>
<blockquote>
<p>Naive Bayes is called naive because it assumes that each input variable is independent.</p>
</blockquote>
<p><img src="http://riboseyim-qiniu.riboseyim.com/ML_Alg_Bayes.png" alt=""></p>
<h2 id="9-降维算法-Dimensional-Reduction"><a href="#9-降维算法-Dimensional-Reduction" class="headerlink" title="9. 降维算法 Dimensional Reduction"></a>9. 降维算法 Dimensional Reduction</h2><p>在机器学习和统计学领域，降维是指在限定条件下，降低随机变量个数，得到一组“不相关”主变量的过程，并可进一步细分为特征选择和特征提取两大方法。</p>
<p>一些数据集可能包含许多难以处理的变量。特别是资源丰富的情况下，系统中的数据将非常详细。在这种情况下，数据集可能包含数千个变量，其中大多数变量也可能是不必要的。在这种情况下，几乎不可能确定对我们的预测影响最大的变量。此时，我们需要使用降维算法，降维的过程中也可能需要用到其他算法，例如借用随机森林，决策树来识别最重要的变量。</p>
<h2 id="10-梯度增强算法-Gradient-Boosting"><a href="#10-梯度增强算法-Gradient-Boosting" class="headerlink" title="10. 梯度增强算法 Gradient Boosting"></a>10. 梯度增强算法 Gradient Boosting</h2><p>梯度增强算法（Gradient Boosting）使用多个弱算法来创建更强大的精确算法。它与使用单个估计量不同，而是使用多个估计量创建一个更稳定和更健壮的算法。梯度增强算法有几种：</p>
<ul>
<li>XGBoost  — 使用线性和树算法</li>
<li>LightGBM  — 只使用基于树的算法<br>梯度增强算法的特点是精度较高。此外，LightGBM 算法具有令人难以置信的高性能。</li>
</ul>
<h2 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><h4 id="《The-Machine-Learning-Master》"><a href="#《The-Machine-Learning-Master》" class="headerlink" title="《The Machine Learning Master》"></a><a target="_blank" rel="noopener" href="https://www.gitbook.com/book/riboseyim/machine-learning">《The Machine Learning Master》</a></h4><p><img src="http://riboseyim-qiniu.riboseyim.com/banner-MLM-201803.png" alt=""></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/01/17/Machine-Learning-TensorFlow/">Machine Learning(一):基于 TensorFlow 实现宠物血统智能识别</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/01/15/Machine-Learning-OpenCV/">Machine Learning(二):宠物智能识别之 Using OpenCV with Node.js</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/02/09/Machine-Learning-Projects/">Machine Learning:机器学习项目</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/02/10/Machine-Learning-Algorithms/">Machine Learning:机器学习算法</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/04/02/Machine-Learning-Algorithms-Sheet/">Machine Learning:如何选择机器学习算法</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/05/07/Machine-Learning-Neural-Network">Machine Learning:神经网络基础</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/01/25/Machine-Learning-Books/">Machine Learning:机器学习书单</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2017/08/29/Machine-Learning-News">Machine Learning:人工智能媒体报道集</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/02/16/Machine-Learning-Law/">Machine Learning:机器学习技术与知识产权法</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2018/03/09/Machine-Learning-Economist/">Machine Learning:经济学家谈人工智能</a></li>
<li><a target="_blank" rel="noopener" href="https://riboseyim.github.io/2017/09/15/Visualization-Graphviz/">数据可视化（三）基于 Graphviz 实现程序化绘图</a></li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.economist.com/blogs/economist-explains/2017/08/economist-explains-24?fsrc=scn/tw/te/bl/ed/">媒体报道|经济学人：What are algorithms?</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-tour-of-the-top-10-algorithms-for-machine-learning-newbies-dde4edffae11">A Tour of The Top 10 Algorithms for Machine Learning Newbies</a></li>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92">维基百科：监督学习</a></li>
<li><a target="_blank" rel="noopener" href="http://www.infoq.com/cn/news/2018/02/ai-engineer-basic-ability?utm_campaign=infoq_content&amp;utm_source=infoq&amp;utm_medium=feed&amp;utm_term=global">AI工程师基础能力：机器学习 | InfoQ</a></li>
<li><a target="_blank" rel="noopener" href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/">Reinforcement Learning 强化学习 Python 3</a></li>
<li><a target="_blank" rel="noopener" href="http://www.infoq.com/cn/articles/teach-you-how-to-read-all-kinds-of-neural-networks?utm_campaign=infoq_content&amp;utm_source=infoq&amp;utm_medium=feed&amp;utm_term=global">教你看懂各种神经网络</a></li>
<li><a target="_blank" rel="noopener" href="http://www.asimovinstitute.org/neural-network-zoo/">神经网络架构</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-cheat-sheet">微软Azure算法图表</a></li>
<li><a target="_blank" rel="noopener" href="http://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/">SAS算法图表</a></li>
<li><a target="_blank" rel="noopener" href="http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/">算法总结</a><br><a target="_blank" rel="noopener" href="http://thinkbigdata.in/best-known-machine-learning-algorithms-infographic/">http://thinkbigdata.in/best-known-machine-learning-algorithms-infographic/</a>)</li>
<li><a target="_blank" rel="noopener" href="https://blog.dataiku.com/machine-learning-explained-algorithms-are-your-friend">算法的优劣对比</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://riboseyim.com/2018/02/10/Machine-Learning-Algorithms/" data-id="ckwgm33m700ev7b1y6hohjnyg" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数学与算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/" rel="tag">架构师</a></li></ul>

    </footer>
  </div>

  
    <div class="article-entry" itemprop="articleBody">
      <p>
      欢迎扫码关注微信公众号获取最新动态，读者交流 QQ 群：338272982 。
      <br>
      </p>
      <p>
        <a href="https://riboseyim.com" title="微信公众号@睿哥杂货铺" rel="fancy-group" class="fancy-ctn fancybox">
          <img src="http://riboseyim-qiniu.riboseyim.com/ID_RiboseYim_201812.png" title="微信公众号@睿哥杂货铺">
        </a>
      </p>
    </div>
    
 
<script src="/jquery/jquery.min.js"></script>

  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =10
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2018/02/16/Machine-Learning-Law/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          AI产业资讯：机器学习技术与知识产权法
        
      </div>
    </a>
  
  
    <a href="/2018/02/09/Machine-Learning-Articles/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">AI技术原理|推荐文献</div>
    </a>
  
</nav>

  
</article>
 
     
  <div class="comments" id="comments">
    
     
       
       
      
      
  </div>
 
  
</section>
           
    <aside id="sidebar">
  
    

  
    
    <div class="widget-wrap">
    
      <div class="widget" id="toc-widget-fixed">
      
        <strong class="toc-title">文章目录</strong>
        <div class="toc-widget-list">
              <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">机器学习算法分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Supervised-learning"><span class="toc-number">2.0.1.</span> <span class="toc-text">监督学习 | Supervised learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Semi-supervised-learning"><span class="toc-number">2.0.2.</span> <span class="toc-text">半监督学习 | Semi-supervised learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-learning"><span class="toc-number">2.0.3.</span> <span class="toc-text">无监督学习 | Unsupervised learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Reinforcement-learning"><span class="toc-number">2.0.4.</span> <span class="toc-text">强化学习 | Reinforcement learning</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%97%E8%A1%A8"><span class="toc-number">3.</span> <span class="toc-text">机器学习算法列表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-Linear-Regression"><span class="toc-number">4.</span> <span class="toc-text">1. 线性回归算法 Linear Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95-Support-Vector-Machine-SVM"><span class="toc-number">5.</span> <span class="toc-text">2. 支持向量机算法(Support Vector Machine,SVM)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%9C%80%E8%BF%91%E9%82%BB%E5%B1%85-k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95-K-Nearest-Neighbors-KNN"><span class="toc-number">6.</span> <span class="toc-text">3. 最近邻居&#x2F;k-近邻算法 (K-Nearest Neighbors,KNN)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-Logistic-Regression"><span class="toc-number">7.</span> <span class="toc-text">4. 逻辑回归算法 Logistic Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95-Decision-Tree"><span class="toc-number">8.</span> <span class="toc-text">5. 决策树算法 Decision Tree</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-k-%E5%B9%B3%E5%9D%87%E7%AE%97%E6%B3%95-K-Means"><span class="toc-number">9.</span> <span class="toc-text">6. k-平均算法 K-Means</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95-Random-Forest"><span class="toc-number">10.</span> <span class="toc-text">7. 随机森林算法 Random Forest</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95-Naive-Bayes"><span class="toc-number">11.</span> <span class="toc-text">8. 朴素贝叶斯算法 Naive Bayes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95-Dimensional-Reduction"><span class="toc-number">12.</span> <span class="toc-text">9. 降维算法 Dimensional Reduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%A2%AF%E5%BA%A6%E5%A2%9E%E5%BC%BA%E7%AE%97%E6%B3%95-Gradient-Boosting"><span class="toc-number">13.</span> <span class="toc-text">10. 梯度增强算法 Gradient Boosting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E9%98%85%E8%AF%BB"><span class="toc-number">14.</span> <span class="toc-text">扩展阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%8AThe-Machine-Learning-Master%E3%80%8B"><span class="toc-number">14.0.1.</span> <span class="toc-text">《The Machine Learning Master》</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">15.</span> <span class="toc-text">参考文献</span></a></li></ol>
          </div>
      </div>
    </div>

  
    

  
    
  
    
  
    

  
    
  
    <!--微信公众号二维码-->


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
      <div  style="width:100%;margin:0 auto; padding:10px 0;text-align:center">
      &copy; 2008 - 2023 RiboseYim&nbsp;
      |&nbsp; Email:&nbsp; <a>riboseyim@gmail.com</a>
      |&nbsp; <a href="https://twitter.com/riboseyim" target="_blank" style="color:#939393;">Twitter</a>
      |&nbsp; <a href="https://github.com/riboseyim" target="_blank" style="color:#939393;">GitHub</a>
      |&nbsp; <a href="https://github.com/riboseyim/riboseyim.com.comment/issues" target="_blank"> 留言箱 Message Box</a>
    </div>
  </div>
  <div class="outer">
    <div  style="width:100%;margin:0 auto; padding:10px 0;text-align:center">
        主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank" style="color:#939393;font-size:80%">Hexo Cafe</a> |
       <a target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/4.0" style="display:inline-block;text-decoration:none;color:#939393;font-size:80%">保持署名-非商业性使用-禁止演绎| License BY-NC-ND 4.0 </a> |
       <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1258500076'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1258500076%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
  </div>
  </div>
</footer>

<script src="/jquery/jquery.min.js"></script>


    </div>
    <nav id="mobile-nav">
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/tags/DevOps" class="mobile-nav-link">DevOps</a>
  
    <a href="/tags/Machine-Learning" class="mobile-nav-link">机器学习</a>
  
    <a href="/tags/Economist" class="mobile-nav-link">经济学人</a>
  
    <a href="/tags/Policy-Law" class="mobile-nav-link">Policy&amp;Law</a>
  
    <a href="/charts" class="mobile-nav-link">图表</a>
  
    <a href="/2017/02/09/eBook" class="mobile-nav-link">电子书</a>
  
    <a href="/2016/05/31/AboutMe" class="mobile-nav-link">关于</a>
  
    <a href="https://riboseyim.com" class="mobile-nav-link">TechBlog</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
    
 


  
  





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>